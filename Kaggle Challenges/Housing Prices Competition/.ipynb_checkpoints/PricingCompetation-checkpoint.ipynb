{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 79)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take Care of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1        2    3    4       5       6      7      8    9    ...    \\\n",
      "0  60.0  65.0   8450.0  7.0  5.0  2003.0  2003.0  196.0  706.0  0.0   ...     \n",
      "1  20.0  80.0   9600.0  6.0  8.0  1976.0  1976.0    0.0  978.0  0.0   ...     \n",
      "2  60.0  68.0  11250.0  7.0  5.0  2001.0  2002.0  162.0  486.0  0.0   ...     \n",
      "3  70.0  60.0   9550.0  7.0  5.0  1915.0  1970.0    0.0  216.0  0.0   ...     \n",
      "4  60.0  84.0  14260.0  8.0  5.0  2000.0  2000.0  350.0  655.0  0.0   ...     \n",
      "\n",
      "      26     27    28     29   30   31   32   33    34      35  \n",
      "0  548.0    0.0  61.0    0.0  0.0  0.0  0.0  0.0   2.0  2008.0  \n",
      "1  460.0  298.0   0.0    0.0  0.0  0.0  0.0  0.0   5.0  2007.0  \n",
      "2  608.0    0.0  42.0    0.0  0.0  0.0  0.0  0.0   9.0  2008.0  \n",
      "3  642.0    0.0  35.0  272.0  0.0  0.0  0.0  0.0   2.0  2006.0  \n",
      "4  836.0  192.0  84.0    0.0  0.0  0.0  0.0  0.0  12.0  2008.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "## In this case, I will replace missing values with Median of corresponding values\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "in_median = SimpleImputer(strategy = 'median')\n",
    "\n",
    "imputed_X = pd.DataFrame(in_median.fit_transform(X.select_dtypes(exclude=['object'])))\n",
    "\n",
    "print(imputed_X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X[col]) == set(X_test[col])]\n",
    "\n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "\n",
    "\n",
    "#Applying one-hot encoding\n",
    "object_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "low_cardinality_cols = [col for col in object_cols if X[col].nunique() < 10]\n",
    "\n",
    "label_X = X.drop(bad_label_cols, axis = 1)\n",
    "label_X_test = X_test.drop(bad_label_cols, axis = 1)\n",
    "\n",
    "\n",
    "oh_encoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "OH_cols_X = pd.DataFrame(oh_encoder.fit_transform(label_X[low_cardinality_cols]))\n",
    "OH_cols_Xtest = pd.DataFrame(oh_encoder.transform(label_X_test[low_cardinality_cols]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the columns with categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (home_data.dtypes == 'object')\n",
    "categorical_var = list(s[s].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the columns with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude= ['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude= ['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_byColumn = drop_X_train.isnull().sum()\n",
    "missing_values_byColumn[missing_values_byColumn>0]\n",
    "\n",
    "##Getting the name of the columns that includes a missing value\n",
    "\n",
    "col_name = [col for col in drop_X_train.columns if drop_X_train[col].isnull().any()]\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the effectiveness of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-e3bc7a0cd50b>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-e3bc7a0cd50b>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    X.isna().sum()|\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#features = ['LotArea','MiscVal','2ndFlrSF','PoolArea','BsmtFinSF2','GrLivArea','TotalBsmtSF', 'GarageCars']\n",
    "\n",
    "X = home_data[features]\n",
    "X.isna().sum()|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the best max_leaf_nodes\n",
    "def get_accuracy(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    acc = MAE(val_y, preds_val)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "    \n",
    "max_leaf = [x for x in range(50, 250)]\n",
    "\n",
    " \n",
    "best_accuracy = {}  \n",
    "for i in range(len(max_leaf)):\n",
    "    best_accuracy[i] = get_accuracy(max_leaf[i], train_X,val_X, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting best n_estimators\n",
    "def get_accuracy(n_estimators, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=4, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    acc = MAE(val_y, preds_val)\n",
    "    return acc\n",
    "\n",
    "best_estimator = [x for x in range(50, 250)]\n",
    " \n",
    "best_accuracy_n_estimator = {}  \n",
    "for i in range(len(max_leaf)):\n",
    "    best_accuracy_n_estimator[i] = get_accuracy(best_estimator[i], train_X,val_X, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#Best max_leaf\n",
    "min_key = min(best_accuracy, key=best_accuracy.get)\n",
    "print(min_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "#Best n_estimator\n",
    "min_key = min(best_accuracy_n_estimator, key=best_accuracy_n_estimator.get)\n",
    "print(min_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=4,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=68, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_on_full_data = RandomForestRegressor(n_estimators=68, max_leaf_nodes=4)\n",
    "rf_model_on_full_data.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea        0\n",
      "MiscVal        0\n",
      "2ndFlrSF       0\n",
      "PoolArea       0\n",
      "BsmtFinSF2     1\n",
      "GrLivArea      0\n",
      "TotalBsmtSF    1\n",
      "GarageCars     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_X = test_data[features]\n",
    "print(test_X.isna().sum())\n",
    "test_X.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(test_X)\n",
    "test_X = sc.transform(test_X)\n",
    "\n",
    "#dummies = pd.get_dummies(test_X.Neighborhood)\n",
    "#df_dummies = pd.concat([test_X, dummies], axis = 'columns')\n",
    "#df_dummies.drop(['Neighborhood'], axis='columns', inplace=True)\n",
    "#test_X = df_dummies\n",
    "\n",
    "\n",
    "test_preds = rf_model_on_full_data.predict(test_X)\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission3.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
